#!/usr/bin/python
"""
Pipeline tool.
"""
import sys
import os
import platform
import logging
import re
import shlex
import subprocess
import tempfile
import click
import yaml

class Hooks(object):
    def __init__(self):
        self.cleanup = ""


class Bash(object):
    """Wrapper for Bash execution."""

    def __init__(self, script, env={}):
        """Initialize with Bash code and optional environment variables."""
        self.success = False
        self.temp = tempfile.NamedTemporaryFile(
            prefix="pipeline-script-", mode='w+t', suffix=".sh", delete=False)
        if os.path.isfile(script):
            content = str(open(script).read())
            self.temp.writelines(content)
        else:
            self.temp.writelines("#!/bin/bash\n" + script)
        self.temp.close()
        # make Bash script executable
        os.chmod(self.temp.name, 0777)

        logging.info("Running script %s", self.temp.name)

        self.args = shlex.split("bash %s" % self.temp.name)
        self.stdout = subprocess.PIPE
        self.stderr = subprocess.STDOUT
        self.shell = False
        self.env = os.environ.copy()
        self.env.update(env)
        self.exit_code = 0

    def process(self):
        """Running the Bash code."""
        try:
            process = subprocess.Popen(
                self.args, stdout=self.stdout, stderr=self.stderr, shell=self.shell, env=self.env)
            out, _ = process.communicate()
            for line in out.split("\n"):
                yield line
            self.exit_code = process.returncode
            logging.info("Exit code has been %d", process.returncode)
            self.success = True if process.returncode == 0 else False
        except OSError as exception:
            self.exit_code = 1
            yield str(exception)

        # removing script
        os.remove(self.temp.name)


class PipelineData(object):
    """Class for keeping pipeline data."""

    def __init__(self, pipeline, tags=[], hooks=None):
        """Initializing pipeline with definition (loaded from a yaml file)."""
        self.pipeline = pipeline
        self.env_list = [{}, {}, {}]
        self.tags = tags
        self.hooks = hooks


class Tasks(object):
    """Class for procressing a list of tasks."""

    def __init__(self, pipeline):
        """Initializing with referenz to pipeline main object."""
        self.pipeline = pipeline

    def process(self, tasks):
        """Processing a group of tasks."""
        logging.info("Processing group of tasks")
        for entry in tasks:
            key = entry.keys()[0]
            if key == "env":
                self.pipeline.data.env_list[2].update(entry[key])
                logging.debug("Updating environment at level 2 with %s",
                              self.pipeline.data.env_list[2])
                continue

            if key == "shell":
                if len(self.pipeline.data.tags) > 0:
                    count = 0
                    if 'tags' in entry[key]:
                        for tag in self.pipeline.data.tags:
                            if tag in entry[key]['tags']:
                                count += 1

                    if count == 0:
                        continue

                # copying and merging environment variables
                env = self.pipeline.data.env_list[0].copy()
                env.update(self.pipeline.data.env_list[1].copy())
                env.update(self.pipeline.data.env_list[2].copy())

                logging.info("Processing Bash code: start")
                shell = Bash(entry[key]['script'], env)
                for line in shell.process():
                    logging.info(" | %s", line)

                if shell.success:
                    logging.info("Processing Bash code: finished")
                else:
                    if len(self.pipeline.data.hooks.cleanup) > 0:
                        env.update({'PIPELINE_RESULT': 'FAILURE'})
                        env.update({'PIPELINE_SHELL_EXIT_CODE': str(shell.exit_code)})
                        cleanup_shell = Bash(self.pipeline.data.hooks.cleanup, env)
                        for line in cleanup_shell.process():
                            logging.info(" | %s", line)
                    logging.error("Pipeline has failed: immediately leaving!")
                    sys.exit(shell.exit_code)
                continue


class Stage(object):
    """Class for representing a name group (title)."""

    def __init__(self, pipeline, title):
        """Initializing with referenz to pipeline main object."""
        self.pipeline = pipeline
        self.title = title

    def process(self, stage):
        """Processing one stage."""
        logging.info("Processing pipeline stage '%s'", self.title)
        for entry in stage:
            key = entry.keys()[0]
            if key == "env":
                self.pipeline.data.env_list[1].update(entry[key])
                logging.debug("Updating environment at level 1 with %s",
                              self.pipeline.data.env_list[1])
                continue

            if key == "tasks":
                tasks = Tasks(self.pipeline)
                tasks.process(entry[key])
                continue


class Pipeline(object):
    """Class for processing a pipeline definition."""

    def __init__(self, pipeline, env={}, tags=[], hooks=None):
        """Initializing pipeline with definition (loaded from a yaml file)."""
        self.data = PipelineData(pipeline, tags, hooks)
        self.data.env_list[0].update(env)

    def run(self):
        """Processing the whole pipeline definition."""
        for entry in self.data.pipeline:
            key = entry.keys()[0]
            if key == "env":
                self.data.env_list[0].update(entry[key])
                logging.debug("Updating environment at level 0 with %s",
                              self.data.env_list[0])
                continue

            if key.startswith("stage"):
                stage = Stage(self, re.match(r"stage\((?P<title>.*)\)", key).group("title"))
                stage.process(entry[key])

        if len(self.data.hooks.cleanup) > 0:
            env = self.data.env_list[0].copy()
            env.update({'PIPELINE_RESULT': 'SUCCESS'})
            env.update({'PIPELINE_SHELL_EXIT_CODE': '0'})
            cleanup_shell = Bash(self.data.hooks.cleanup, env)
            for line in cleanup_shell.process():
                logging.info(" | %s", line)


def setup_logging():
    """Setup of application logging."""
    logging_format = "%(asctime)-15s %(message)s"
    logging.basicConfig(format=logging_format, level=logging.DEBUG)


@click.command()
@click.option('--definition', help="Pipeline definition in yaml format")
@click.option('--tags', default='', help="Comma separated list of tags")
def main(definition="", tags=""):
    """Pipeline tool."""
    setup_logging()
    logging.info("Running with Python %s", sys.version.replace("\n", ""))
    logging.info("Running on platform %s", platform.platform())
    logging.info("Processing pipeline definition '%s'", definition)

    document = yaml.load(open(definition).read())
    tag_list = [] if  len(tags) == 0 else tags.split(",")

    hooks = Hooks()
    if 'hooks' in document:
        if 'cleanup' in document['hooks']:
            hooks.cleanup = document['hooks']['cleanup']['script']

    if 'matrix' in document:
        matrix = document['matrix']
        for entry in matrix:
            logging.info("Processing pipeline for matrix entry '%s'", entry['name'])
            pipeline = Pipeline(document['pipeline'], env=entry['env'], tags=tag_list, hooks=hooks)
            pipeline.run()
    else:
        pipeline = Pipeline(document['pipeline'], tags=tag_list, hooks=hooks)
        pipeline.run()


if __name__ == "__main__":
    main()
